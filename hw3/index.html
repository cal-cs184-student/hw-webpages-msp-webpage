<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Name: Michael Setchko Palmerlee </div>

		<br>

		Link to webpage: (TODO) <a href="https://cs184.eecs.berkeley.edu/sp25">cs184.eecs.berkeley.edu/sp25</a>
		Link to GitHub repository: (TODO) <a href="https://cs184.eecs.berkeley.edu/sp25">cs184.eecs.berkeley.edu/sp25</a>
		
		<figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>You can add images with captions!</figcaption>
		</figure>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		Give a high-level overview of what you implemented in this homework. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.

		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		Generating rays from the camera is how we estimate the light entering the 
		camera from the scene. For each pixel in the framebuffer, we generate a certain 
		number of rays which go through a randomized point inside the pixel. By averaging 
		the estimated radiance in each of these rays, we can get a more accurate 
		representation of the pixel's color. For each of these rays, we also need to 
		find out where it intersects with the scene in order to simulate a real ray 
		of light. I implemented algorithms which tested rays for intersection with a 
		triangle as well as a sphere. For triangle intersection, I used the Moller 
		Trumbore algorithm. This algorithm first calculates the vectors representing 
		two edges of the triangle. If the cross product of these edges is parallel to 
		the ray direction, then there is no intersection. Then, we perform a series of vector calculations 
		on these vectors as well as the ray origin and direction vectors in order to 
		find the values \( t, \beta, \gamma \), which represent the distance along the 
		ray where it intersects the triangle's plane, and 2 of the barycentric coordinates 
		for the location of the intersection on the triangle. We can easily find \( \alpha \) 
		from the other two barycentric coordinates. If any of the barycentric coordinates 
		generated are negative, then there is no intersection.


		<p>Here are some example renderings with triangle and sphere ray intersection and normal shading</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="img/CBspheres.png" width="400px"/>
				  <figcaption>Rendering of a scene with sphere intersection</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="img/CBgems.png" width="400px"/>
				  <figcaption>Rendering of a scene with triangle intersection</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="img/cow.png" width="400px"/>
				  <figcaption>Cow.</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		In my BVH construction algorithm, I used the average z value of all of the 
		centroids of the bounding boxes of the items in each node as the splitting 
		heuristic. Using this, I split the primitives into two collections and use those 
		collections to recursively call the construction algorithm again on each side 
		of the split. If the algorithm is called on a collection of primitives that 
		is less than or equal to the max leaf size, then I create a leaf node.

		<br/>
		<br/>

		<p>Here are some example renderings of more complex scenes that would take a long 
		time without any BVH acceleration:</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="img/lucy.png" width="400px"/>
				  <figcaption>Rendering of CBlucy.dae file</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="img/planck.png" width="400px"/>
				  <figcaption>Rendering of maxplanck.dae file</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="img/cow.png" width="400px"/>
				  <figcaption>Cow.</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		I compared the rendering times of CBlucy.dae both with and without BVH 
		acceleration to see how much speed up I achieved. Without BVH acceleration, 
		it took roughly 86 seconds to render this scene. With BVH, it took a mere 1.8 
		seconds. With complex scenes like this where there are many triangles in the 
		mesh, BVH provides a very large speedup. This is because without BVH, we have 
		to perform an intersection test on every single triangle in the mesh every 
		time we are evaluating a ray. With BVH, we only have to do \( O(\log(n)) \), 
		where \( n \) is the number of triangles,
		plane intersection tests to find BVH intersections down to a leaf node, and 
		then do triangle intersection tests on the triangles in the leaf 
		node, which is much fewer than the total number of triangles.

		<h2>Part 3: Direct Illumination</h2>
		The first implementation of direct lighting used uniform hemisphere sampling. 
		First, we trace a ray to find its intersection with the scene, if there is one. 
		Then, from the intersection point, we take uniformly random samples from the 
		hemisphere centered on the surface normal at the intersection. We then find the 
		zero-bounce radiance of these sample rays, input the values into the BSDF of the 
		surface, and calculate the average reflected radiance in the original ray's direction.

		<br/>
		<br/>

		The importance sampling equation is similar, but instead of sampling uniformly 
		from a hemisphere above the intersection point, we sample a fixed number of 
		times from each light source using the <code>sample_L()</code> function. This 
		ensures that all of our samples will come from light sources, so will all 
		contribute to the reflected radiance. Since we can't take an infinite number 
		of samples, this ensures that we will get valuable samples at every intersection 
		point. The goal is to simulate taking a very large number of samples over the 
		whole hemisphere without actually doing all that computing work.

		<p>Here are some examples of renderings using both of these sampling techniques</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="img/CBbunny_H_64_32.png" width="400px"/>
				  <figcaption>Uniform hemisphere sampling, bunny</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="img/spheres_H_64_32.png" width="400px"/>
				  <figcaption>Uniform hemisphere sampling, spheres</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="img/CBbunny_64_32.png" width="400px"/>
				  <figcaption>Importance sampling, bunny</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="img/spheres_64_32.png" width="400px"/>
				  <figcaption>Importance sampling, spheres</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<p>We will focus on the bunny scene and compare different values for sampling numbers</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="img/bunny_1_1.png" width="400px"/>
				  <figcaption>1 ray per pixel, 1 light ray</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="img/bunny_1_64.png" width="400px"/>
				  <figcaption>1 ray per pixel, 64 light rays</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="img/bunny_64_1.png" width="400px"/>
				  <figcaption>64 rays per pixel, 1 light ray</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="img/bunny_64_4.png" width="400px"/>
				  <figcaption>64 rays per pixel, 4 light rays</figcaption>
				</td>
			  </tr>
				<tr>
					<td style="text-align: center;">
						<img src="img/bunny_64_16.png" width="400px"/>
						<figcaption>64 rays per pixel, 16 light ray</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="img/bunny_64_64.png" width="400px"/>
						<figcaption>64 rays per pixel, 64 light rays</figcaption>
					</td>
					</tr>
			</table>
		</div>

		As we can see in the comparison images between uniform hemisphere and importance 
		sampling, uniform hemisphere sampling creates a much noisier image. This 
		is to be expected, because we are randomly sampling from the hemisphere above 
		an intersection, meaning that we are not guaranteed to sample from a light source 
		if one exists. This creates dark intersection pixels where the light source was either not 
		sampled or inadequately sampled. With importance sampling, we have a much 
		smoother image with no noise, because we are ensuring that all of our light ray 
		reflection samples come from a light source, if one is in line of sight of the 
		ray intersection point.

		<h2>Part 4: Global Illumination</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 5: Adaptive Sampling</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>(Optional) Part 6: Extra Credit Opportunities</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
		
		<h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul>
		</div>
	</body>
</html>